{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHARK QUEST\n",
    "## New Kids On The Block\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Pickle ?\n",
    "- Column names?\n",
    "\n",
    "## Selecting\n",
    "- Select relevant columns\n",
    "- Analyse relevant columns\n",
    "\n",
    "## Cleaning :\n",
    "- Cast to appropriate data types\n",
    "    - General cleaning\n",
    "        - identify duplicates\n",
    "            - fuzzy\n",
    "        - removing duplicates\n",
    "            - remove\n",
    "            - merge\n",
    "        - handling null values\n",
    "            - remove\n",
    "            - replace\n",
    "        - manipulating strings\n",
    "        - formatting the data.\n",
    "\n",
    "- Wrong inputs\n",
    "- Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "### TIME\n",
    "- Shark attacks are seasonal (Summer)\n",
    "- Shark attacks are increasing \n",
    "- Shark attacks are more concentrated in the PM \n",
    "\n",
    "### LOCATION\n",
    "- Some countries are more attack prone (Australia)\n",
    "- Some countries are more likely to be fatal (Australia)\n",
    "\n",
    "\n",
    "### DEMOGRAPHICS\n",
    "- Males are more likely to get attacked\n",
    "- Males are more likely to get provoke a shark\n",
    "- Provoked attacked are more fatal\n",
    "- Young persons are more likely to get attacked\n",
    "- Old persons are more likely to get killed\n",
    "\n",
    "- Names more likely to get attacked (John)\n",
    "\n",
    "### OTHER\n",
    "- Some species are more aggressive (Tiger Shark)\n",
    "- Some activities are more likely (Surfing)\n",
    "- Some activities are more fatal\n",
    "\n",
    "- Full moon? ðŸ˜‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Ideas\n",
    "\n",
    "- App that gives a likelyhood of attack based on location and time\n",
    "- Vacations far away from sharks for phobics\n",
    "- Witness attacks for masochists\n",
    "\n",
    "- Surf school at the safest places / seasons\n",
    "- Fishing supplies => shark repellant by activities\n",
    "- Safety training to avoid provocations / live in harmony\n",
    "\n",
    "- Shark repellant => best spots\n",
    "- Insurance for surfers, premiums for high risk areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL CLEANING\n",
    "1. Rename columns\n",
    "2. Drop columns\n",
    "3. Remove duplicates\n",
    "    - Remove full dupes\n",
    "    - Remove fuzzy search\n",
    "4. Strip values\n",
    "\n",
    "### SPECIFIC CLEANING\n",
    "1. Search / Replace / Reformat strings\n",
    "2. Merge categories\n",
    "3. Cast to Null\n",
    "4. Cast correct type\n",
    "5. Create new columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the data\n",
    "shark_attacks = pd.read_excel('GSAF5.xls')\n",
    "\n",
    "shark_attacks[shark_attacks[['Case Number', 'Name']].duplicated(keep=False) & ~shark_attacks['Case Number'].isna()]\n",
    "shark_attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "pd.set_option('display.max_rows', 80)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "shark_attacks.columns = [col.strip().replace(\" \", \"_\").replace(\n",
    "    \".\", \"\").lower() for col in shark_attacks.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = {\n",
    "    'type': {'dtype': 'category', 'categories': ['PROVOKED', 'UNPROVOKED', 'INVALID']},\n",
    "    'date': {'dtype': 'datetime64[ns]'},\n",
    "    'country': {'dtype': 'string'},\n",
    "    'state': {'dtype': 'string'},\n",
    "    'location': {'dtype': 'string'},\n",
    "    'activity': {'dtype': 'category'},\n",
    "    'severity': {'dtype': 'category', 'categories': ['FATALITY', 'INJURY', 'OTHER']},\n",
    "    'injury': {'dtype': 'string'},\n",
    "    'time': {'dtype': 'category', 'categories': ['MORNING', 'NOON', 'AFTERNOON', 'DANW', 'NIGHT', 'DUSK']}\n",
    "}\n",
    "\n",
    "business_relevant_columns = ['date', 'type', 'country',\n",
    "                             'state', 'location', 'activity', 'injury', 'time']\n",
    "display(business_relevant_columns)\n",
    "shark_attacks[business_relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "# relevant_columns = [col for col in data_schema]\n",
    "# Use boolean indexing to filter columns\n",
    "# dropped_columns = shark_attacks.columns[~shark_attacks.columns.isin(relevant_columns)]\n",
    "# display(dropped_columns)\n",
    "# shark_attacks = shark_attacks.loc[:, relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "#Drop perfect duplicates\n",
    "shark_attacks.drop_duplicates(keep=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hennings functions\n",
    "# Merge categories : (*categories to be merged, target) - Henning\n",
    "\n",
    "\n",
    "def merge_values(row, arg1, *args):\n",
    "    if row in args:\n",
    "        return arg1\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "\n",
    "shark_attacks['type'].unique()\n",
    "\n",
    "shark_attacks['type'] = shark_attacks['type'].apply(merge_values, args=(\n",
    "    \"Invalid\", \"Questionable\", \"Unconfirmed\", \"?\", 'Unverified', 'Under investigation'))\n",
    "shark_attacks['type'] = shark_attacks['type'].apply(\n",
    "    merge_values, args=(\"Provoked\", \" Provoked\"))\n",
    "shark_attacks['type'] = shark_attacks['type'].apply(\n",
    "    merge_values, args=(\"Watercraft\", \"Boat\"))\n",
    "\n",
    "shark_attacks['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linh functions\n",
    "# Strip function : strips spaces - Linh\n",
    "def strip_func(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_cleaned = strip_func(shark_attacks)\n",
    "df_cleaned.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['location'] = df_cleaned['location'].astype(str)\n",
    "\n",
    "\n",
    "def clean_data(location):\n",
    "    location = re.sub(r'\\d{1,2}Âº[NS],\\s*\\d{1,3}Âº[EW]', '', location)\n",
    "    location = re.sub(r'\\(.*?\\)', '', location)\n",
    "    location = re.sub(r'\\s+', ' ', location)\n",
    "    return location.title()\n",
    "\n",
    "\n",
    "df_cleaned['location'] = df_cleaned['location'].apply(clean_data)\n",
    "df_cleaned['location'].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    (r\"swimming|wading\", \"Swimming\"),\n",
    "    (r\"surf|boogie boarding|paddle|foil\", \"Surfing\"),\n",
    "    (r\"fish|fishing|spearfish|kayak\", \"Fishing\"),\n",
    "    (r\"diving|scuba|freediving|snorkel\", \"Diving\"),\n",
    "    (r\"sit|stand\", \"Passive\"),\n",
    "]\n",
    "\n",
    "\n",
    "def categorize_activity(activity):\n",
    "    if pd.isna(activity):\n",
    "        return \"Invalid\"\n",
    "\n",
    "    activity = activity.lower()\n",
    "\n",
    "    for pattern, label in categories:\n",
    "        if re.search(pattern, activity):\n",
    "            return label\n",
    "\n",
    "    return \"Other Activity\"\n",
    "\n",
    "\n",
    "df_cleaned['activity'] = df_cleaned['activity'].apply(categorize_activity)\n",
    "df_cleaned.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricardo functions\n",
    "# Replace as Nan, Nat, ... function - Ricardo\n",
    "# Remove obvious duplicate (entire line) - Ricardo\n",
    "# Remove fuzzy duplicates (case number? dates?) - Ricardo\n",
    "\n",
    "\"\"\" def repnan(schema, series, keys, value=nd.nan):\n",
    "\n",
    "    # fills all\n",
    "\n",
    "    # takes a list of values, replace with value OR <NaN> if no value is provided\n",
    "    return series.replace(keys, value, inplace=True) \"\"\"\n",
    "\n",
    "def repnan(series, keys, value=np.nan):\n",
    "    \"\"\"\n",
    "    input schema as data_schema for column types\n",
    "    input series as dataframe['Column']\n",
    "    input keys as a list of all the keys to replace\n",
    "    input value as the replacer value for the keys, default is NaN\n",
    "    \"\"\"\n",
    "    # fills all\n",
    "\n",
    "    # takes a list of values, replace with value OR <NaN> if no value is provided\n",
    "    return series.replace(keys, value, inplace=True)\n",
    "    # changes series.type to match schema\n",
    "    # output = series.astype(schema[series.name])\n",
    "\n",
    "    #return output\n",
    "    \n",
    "repnan(shark_attacks[\"Name\"].fillna(np.nan).str.strip(),['male', 'female'],np.nan)\n",
    "shark_attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jp functions\n",
    "\n",
    "# replacements\n",
    "replacements_test_species = [\n",
    "    (r'^.*([Tt]iger).*$', 'TIGER SHARK'),\n",
    "]\n",
    "\n",
    "replacements_test_dates = [\n",
    "    (r'^(.*)(\\d{2})(.*)(\\w{3})(.*)(\\d{4})(.*)', r'\\2-\\4-\\6'),\n",
    "    (r'^(.*)(\\w{3})(.*)(\\d{4})(.*)', r'01-\\2-\\4'),\n",
    "    (r'-(uly|une)', r'-J\\1'),\n",
    "]\n",
    "\n",
    "replacements_test_time = [\n",
    "    (r'^.*((0[0-2]|23)h|([nN]ight|[dD]ark)).*$', 'NIGHT'),\n",
    "    (r'^.*((0[3-6])h|([dD]awn|[sS]unrise|[dD]aybreak)).*$', 'DAWN'),\n",
    "    (r'^.*((0[7-9]|10)h.*$|([mM]orning|^[aA]\\.?[mM])).*$', 'MORNING'),\n",
    "    (r'^.*((1[1-4])h.*$|([nN]oon|[mM]idday|[lL]unch)).*$', 'NOON'),\n",
    "    (r'^.*((1[5-8])h.*$|([aA]fternoon|^[pP]\\.?[mM])).*$', 'AFTERNOON'),\n",
    "    (r'^.*((19|2[0-2])h.*$|([dD]usk|[sS]unset|[eE]vening)).*$', 'DUSK'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_string_patterns(value, replacements):\n",
    "\n",
    "    if isinstance(value, str):\n",
    "\n",
    "        for pattern, target in replacements:\n",
    "            value = re.sub(pattern, target, value)\n",
    "        return value\n",
    "\n",
    "    else:\n",
    "\n",
    "        return value\n",
    "\n",
    "\n",
    "species_replace = shark_attacks['Species '].apply(\n",
    "    replace_string_patterns, replacements=replacements_test_species)\n",
    "display(species_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATE TEST\n",
    "date_replace_test = shark_attacks['date'].apply(\n",
    "    replace_string_patterns, replacements=replacements_test_dates,)\n",
    "date_test = pd.to_datetime(date_replace_test, format='mixed', errors='coerce')\n",
    "\n",
    "formatted_dates = date_test.dt.strftime('%d-%m-%Y')\n",
    "formatted_dates = formatted_dates.astype('datetime64[ns]')\n",
    "formatted_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME TEST\n",
    "display(shark_attacks['time'].value_counts())\n",
    "time_replace_test = shark_attacks['time'].apply(\n",
    "    replace_string_patterns, replacements=replacements_test_time,)\n",
    "display(time_replace_test.value_counts())\n",
    "time_replace_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_categories = [value for key, value in replacements_test_time]\n",
    "# PRINT ALL COLUMNS WITH FIRST VALUE\n",
    "shark_attacks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source, PDF, Case Number as possible duplicate finder or year / date fill\n",
    "relevant_columns = ['date', 'Year', 'type', 'country', 'state', 'location', 'activity',\n",
    "                    'Name', 'Sex', 'Age', 'injury', 'time', 'Species', 'Source', 'pdf', 'href formula', 'href']\n",
    "business_relevant_columns = ['date', 'type', 'country',\n",
    "                             'state', 'location', 'activity', 'injury', 'time']\n",
    "\n",
    "# Henning : Date, Type\n",
    "# Ricardo : Country, State\n",
    "# Linh : Location, Activity\n",
    "# Jp : Injury, Time\n",
    "\n",
    "# Type : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Provoked, Unprovoked, Invalid\n",
    "# Date : datetime : Clean \"Reported\" - Harmonize Format - Cast weird into NaT. Final => Dates (as datetime), NaT\n",
    "# Country : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# State : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Location : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Activity : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Few categories to be determined\n",
    "# Injury : category : Merge columns based on keywords. Nan into other. Final => Fatality, Injury, Other\n",
    "# Time : category : Cast into categories Final => morning (6-10) noon (10-14) afternoon( 14-18) dusk (18-22) night (22 - 2) dawn (2-6) maybe as integers (0-5)\n",
    "\n",
    "display(time_replace_test.value_counts())\n",
    "where_test = time_replace_test.where(time_replace_test.isin(valid_categories))\n",
    "where_test = where_test.astype('category')\n",
    "where_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETYPE COLUMNS\n",
    "columns_types = {key: value['dtype'] for key, value in data_schema.items()}\n",
    "print(columns_types)\n",
    "shark_attacks.astype(columns_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT ALL COLUMNS WITH FIRST VALUE\n",
    "shark_attacks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source, PDF, Case Number as possible duplicate finder or year / date fill\n",
    "relevant_columns = ['date', 'Year', 'type', 'country', 'state', 'location', 'activity',\n",
    "                    'Name', 'Sex', 'Age', 'injury', 'time', 'Species', 'Source', 'pdf', 'href formula', 'href']\n",
    "business_relevant_columns = ['date', 'type', 'country',\n",
    "                             'state', 'location', 'activity', 'injury', 'time']\n",
    "\n",
    "# Henning : Date, Type\n",
    "# Ricardo : Country, State\n",
    "# Linh : Location, Activity\n",
    "# Jp : Injury, Time\n",
    "\n",
    "# Type : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Provoked, Unprovoked, Invalid\n",
    "# Date : datetime : Clean \"Reported\" - Harmonize Format - Cast weird into NaT. Final => Dates (as datetime), NaT\n",
    "# Country : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# State : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Location : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Activity : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Few categories to be determined\n",
    "# Injury : category : Merge columns based on keywords. Nan into other. Final => Fatality, Injury, Other\n",
    "# Time : category : Cast into categories Final => morning (6-10) noon (10-14) afternoon( 14-18) dusk (18-22) night (22 - 2) dawn (2-6) maybe as integers (0-5)\n",
    "\n",
    "# Todo\n",
    "# Remove obvious duplicate (entire line) - Ricardo\n",
    "# Remove fuzzy duplicates (case number? dates?) - Ricardo\n",
    "\n",
    "# Functions :\n",
    "# Merge categories : (*categories to be merged, target) - Henning\n",
    "# Strip function : strips spaces - Linh\n",
    "# Replace as Nan, Nat, ... function - Ricardo\n",
    "# DONE - Replace by keyword function - Jp\n",
    "# DONE - Cast to dateTime function\n",
    "# Matching function (find similarities, keyword based?)\n",
    "# DONE - Reformat dates, strings\n",
    "# Filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_rows = shark_attacks[shark_attacks['injury'].str.contains(\n",
    "    'FATAL', case=False, na=False)]\n",
    "\n",
    "print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT MULTIPLE COLUMNS\n",
    "\n",
    "display(shark_attacks[['Case Number', 'Case Number.1']].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"Unnamed\"\n",
    "unnamed_columns = shark_attacks[shark_attacks.filter(\n",
    "    regex=pattern).columns].dropna(thresh=1)\n",
    "display(unnamed_columns.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT ALL MISFORMATED DATES (YEAR END \\d{4})\n",
    "shark_attacks[~shark_attacks['date'].str.contains(\n",
    "    r'.*\\d{4}$', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks['Name'].value_counts()\n",
    "\n",
    "\n",
    "def get_fname(row):\n",
    "    return str(row).split()[0]\n",
    "\n",
    "\n",
    "shark_attacks['first_name'] = shark_attacks['Name'].apply(get_fname)\n",
    "\n",
    "shark_attacks['first_name'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INJURY\n",
    "\n",
    "## Problems\n",
    "- Some are non-human damages (boat, kayak, boards)\n",
    "- Some are non injuries (touched shark)\n",
    "- Some don't have details\n",
    "- Fatalities flags are non consistent\n",
    "- Some incident are post-mortem\n",
    "- Some are not incidents ('Aboriginal rock carving depicts man being attacked by a shark')\n",
    "- Nan\n",
    "\n",
    "## Additional\n",
    "- Some provoked details that could be useful if missing elsewhere\n",
    "\n",
    "## Solutions\n",
    "- 3 categories : \n",
    "    - Fatality\n",
    "    - Injury\n",
    "    - Other\n",
    "\n",
    "- Keyword(s) based search / replace ?\n",
    "\n",
    "### TIME\n",
    "\n",
    "## Problems\n",
    "- Lots of Nan\n",
    "- Some are times (12h00,...), other are time of day (morning,...)\n",
    "- Some are text\n",
    "- Some are ranges\n",
    "- Some are calculations\n",
    "- Some are 12h based, other 24h based\n",
    "- Some maybe duplicates \n",
    "- Some are misplaced data\n",
    "\n",
    "## Solutions\n",
    "- 2 types :\n",
    "    - Time (int? str?)\n",
    "    - Unknown / NaN / None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
