{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHARK QUEST\n",
    "## New Kids On The Block\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Pickle ?\n",
    "- Column names?\n",
    "\n",
    "## Selecting\n",
    "- Select relevant columns\n",
    "- Analyse relevant columns\n",
    "\n",
    "## Cleaning :\n",
    "- Cast to appropriate data types\n",
    "    - General cleaning\n",
    "        - identify duplicates\n",
    "            - fuzzy\n",
    "        - removing duplicates\n",
    "            - remove\n",
    "            - merge\n",
    "        - handling null values\n",
    "            - remove\n",
    "            - replace\n",
    "        - manipulating strings\n",
    "        - formatting the data.\n",
    "\n",
    "- Wrong inputs\n",
    "- Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "### TIME\n",
    "- Shark attacks are seasonal (Summer)\n",
    "- Shark attacks are increasing \n",
    "- Shark attacks are more concentrated in the PM \n",
    "\n",
    "### LOCATION\n",
    "- Some countries are more attack prone (Australia)\n",
    "- Some countries are more likely to be fatal (Australia)\n",
    "\n",
    "\n",
    "### DEMOGRAPHICS\n",
    "- Males are more likely to get attacked\n",
    "- Males are more likely to get provoke a shark\n",
    "- Provoked attacked are more fatal\n",
    "- Young persons are more likely to get attacked\n",
    "- Old persons are more likely to get killed\n",
    "\n",
    "- Names more likely to get attacked (John)\n",
    "\n",
    "### OTHER\n",
    "- Some species are more aggressive (Tiger Shark)\n",
    "- Some activities are more likely (Surfing)\n",
    "- Some activities are more fatal\n",
    "\n",
    "- Full moon? ðŸ˜‚\n",
    "\n",
    "\n",
    "Retained :\n",
    "- Shark Species have a gender preference (score) => JP => Heinning\n",
    "- Some countries are more provocative against sharks* => Ricardo\n",
    "- Shark attacks are more concentrated in the PM => Linh\n",
    "\n",
    "- Names more likely to get attacked (John) => JP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Ideas\n",
    "\n",
    "- App that gives a likelyhood of attack based on location and time\n",
    "- Vacations far away from sharks for phobics\n",
    "- Witness attacks for masochists\n",
    "\n",
    "- Surf school at the safest places / seasons\n",
    "- Fishing supplies => shark repellant by activities\n",
    "- Safety training to avoid provocations / live in harmony\n",
    "\n",
    "- Shark repellant => best spots\n",
    "- Insurance for surfers, premiums for high risk areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL CLEANING\n",
    "1. Rename columns\n",
    "2. Drop columns\n",
    "3. Remove duplicates\n",
    "    - Remove full dupes\n",
    "    - Remove fuzzy search\n",
    "4. Strip values\n",
    "5. Reset Index\n",
    "\n",
    "### SPECIFIC CLEANING\n",
    "1. Search / Replace / Reformat strings\n",
    "2. Merge categories\n",
    "3. Cast to Null\n",
    "4. Cast correct type\n",
    "5. Create new columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import depedencies\n",
    "#from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "shark_attacks_df = pd.read_excel('GSAF5.xls')\n",
    "shark_attacks = shark_attacks_df.copy()\n",
    "\n",
    "countries_df = pd.read_csv('country_coord.csv')\n",
    "countries = countries_df.copy()\n",
    "\n",
    "shark_attacks.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "pd.set_option('display.max_rows', 80)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format all columns names\n",
    "shark_attacks.columns = [col.strip().replace(\" \", \"_\").replace(\".\", \"\").lower() for col in shark_attacks.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def merge_values(row, arg1, *args):\n",
    "    if row in args:\n",
    "        return arg1\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "\n",
    "def strip_values(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_to_nan(series, keys, value=np.nan):\n",
    "    \"\"\"\n",
    "    input series as dataframe['Column']\n",
    "    input keys as a list of all the keys to replace\n",
    "    input value as the replacer value for the keys, default is NaN\n",
    "    \"\"\"\n",
    "\n",
    "    return series.replace(keys, value, inplace=True)\n",
    "\n",
    "\n",
    "def categorize_activity(activity):\n",
    "    if pd.isna(activity):\n",
    "        return \"Invalid\"\n",
    "\n",
    "    activity = activity.lower()\n",
    "\n",
    "    for pattern, label in categories:\n",
    "        if re.search(pattern, activity):\n",
    "            return label\n",
    "\n",
    "    return \"Other Activity\"\n",
    "\n",
    "\n",
    "def replace_string_patterns(value, replacements):\n",
    "\n",
    "    if isinstance(value, str):\n",
    "\n",
    "        for pattern, result in replacements:\n",
    "            value = re.sub(pattern, result, value)\n",
    "        return value\n",
    "\n",
    "    else:\n",
    "\n",
    "        return value\n",
    "    \n",
    "def json_to_dict(json_filename):\n",
    "    with open(json_filename+\".json\", \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract\n",
    "\n",
    "data_schema = json_to_dict('schema')\n",
    "\n",
    "\"\"\" data_schema_in = {\n",
    "    'type': {'dtype': 'category', 'categories': ['PROVOKED', 'UNPROVOKED', 'WATERCRAFT','INVALID']},\n",
    "    'date': {'dtype': 'datetime64[ns]'},\n",
    "    'country': {'dtype': 'string'},\n",
    "    'state': {'dtype': 'string'},\n",
    "    'location': {'dtype': 'string'},\n",
    "    'activity': {'dtype': 'category', 'categories': ['SWIMMING', 'SURFING', 'FISHING', 'DIVING', 'PASSIVE', 'BOATING']},\n",
    "    'severity': {'dtype': 'category', 'categories': ['FATALITY', 'INJURY', 'OTHER']},\n",
    "    'time': {'dtype': 'category', 'categories': ['MORNING', 'NOON', 'AFTERNOON', 'DANW', 'NIGHT', 'DUSK']}\n",
    "} \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new columns\n",
    "shark_attacks['severity'] = shark_attacks_df['Injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns\n",
    "shark_attacks = shark_attacks[[col for col in data_schema]]\n",
    "shark_attacks['species'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip strings\n",
    "shark_attacks = shark_attacks.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "shark_attacks.replace(['N/A', 'null', '--'], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "#Drop complete duplicates\n",
    "shark_attacks.drop_duplicates(keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Index\n",
    "shark_attacks.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat values\n",
    "replacements = json_to_dict('replacements')\n",
    "\n",
    "r\"\"\" replacements_in = {\n",
    "    \n",
    "    'type': [\n",
    "        (r'^.*?(Provoked).*$', 'PROVOKED'),\n",
    "        (r'^.*?(Unprovoked|Disaster).*$', 'UNPROVOKED'),\n",
    "        (r'^.*?(Watercraft|Boat).*$', 'WATERCRAFT'),\n",
    "    ],\n",
    "\n",
    "    'activity': [\n",
    "        (r'^.*?([Ss]wimming|[Ww]ading|[Bb]athing|[Ff]el|[Ss]plashing|[Ff]loat|[Dd]isaster|Dangling|Jump).*$', 'SWIMMING'),\n",
    "        (r'^.*?([Sf]urf|[Bb]oard|[Pp]addl|[Ff]oil).*$', 'SURFING'),\n",
    "        (r'^.*?([Dd]iving|[Ss]cuba|[Ss]norkel|[Sp]ear|[Ww]reck).*$', 'DIVING'),\n",
    "        (r'^.*?([Bb]oat|[Sa]il|[Rr]ow|[Cc]raft|[Kk]ayak|[Cc]ano).*$', 'BOATING'),\n",
    "        (r'^.*?(Fishing|Clam).*$', 'FISHING'),\n",
    "        (r'^.*?([Ss]it|[Ss]tand|[Pp]lay|Murder|[Tt]read|[Ww]alk).*$', 'PASSIVE'),\n",
    "    ],\n",
    "    \n",
    "    'time': [\n",
    "        (r'^.*((0[0-2]|23)h|([nN]ight|[dD]ark)).*$', 'NIGHT'),\n",
    "        (r'^.*((0[3-6])h|([dD]awn|[sS]unrise|[dD]aybreak)).*$', 'DAWN'),\n",
    "        (r'^.*((0[7-9]|10)h.*$|([mM]orning|^[aA]\\.?[mM])).*$', 'MORNING'),\n",
    "        (r'^.*((1[1-4])h.*$|([nN]oon|[mM]idday|[lL]unch)).*$', 'NOON'),\n",
    "        (r'^.*((1[5-8])h.*$|([aA]fternoon|^[pP]\\.?[mM])).*$', 'AFTERNOON'),\n",
    "        (r'^.*((19|2[0-2])h.*$|([dD]usk|[sS]unset|[eE]vening|[Ii]njured)).*$', 'DUSK'),\n",
    "    ],\n",
    "    \n",
    "    'date': [\n",
    "        (r'^(.*)(\\d{2})(.*)(\\w{3})(.*)(\\d{4})(.*)', r'\\2-\\4-\\6'),\n",
    "        (r'^(.*)(\\w{3})(.*)(\\d{4})(.*)', r'01-\\2-\\4'),\n",
    "        (r'-(uly|une)', r'-J\\1'),\n",
    "    ],\n",
    "    \n",
    "    'severity': [\n",
    "        (r'^.*([Fa]tal|FATAL|[Kk]illed).*$', r'FATALITY'),\n",
    "        (r'^.*(^[Ii]nju|[Bb]it|[Ss]urvived|[Ll]acer|[Mm]inor|[Ii]njured|[Aa]bra|[Pp]unct|[Mm]ultiple|[Ss]cratches|[Rr]iped|[Gg]ash).*$', r'INJURY'),\n",
    "    ],\n",
    "    \n",
    "    'country': [\n",
    "        (r'^.*([Fa]tal|FATAL|[Kk]illed).*$', r'FATALITY'),\n",
    "    ],\n",
    "}\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col, values in replacements.items():\n",
    "    shark_attacks[col] = shark_attacks[col].apply(\n",
    "        replace_string_patterns, replacements=values)\n",
    "shark_attacks['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks['country'] = shark_attacks['country'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "replace_to_nan(shark_attacks[\"country\"], [\"england\",\"scotland\"], \"united kingdom\")\n",
    "replace_to_nan(shark_attacks[\"country\"], [\"usa\", \"hawaii\"], \"united states\")\n",
    "replace_to_nan(shark_attacks[\"country\"], [\"reunion\"], \"france\")\n",
    "replace_to_nan(shark_attacks[\"country\"], [\"columbia\"], \"colombia\")\n",
    "replace_to_nan(shark_attacks[\"country\"], [\"new guinea\"], \"papua new guinea\")\n",
    "\n",
    "\n",
    "# unify country, converts all low value \"country\" ocorrences into <NA>. Also sets Country as string-type\n",
    "country_list = [x.lower() for x in countries['Country']]\n",
    "shark_attacks[\"country\"] = shark_attacks[\"country\"].where(shark_attacks[\"country\"].isin(country_list), np.nan)\n",
    "shark_attacks['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean dates\n",
    "shark_attacks['date'] = pd.to_datetime(shark_attacks['date'], errors='coerce')\n",
    "shark_attacks['date'] = shark_attacks['date'].dt.strftime('%d-%m-%Y')\n",
    "shark_attacks['date'] = shark_attacks['date'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast correct types\n",
    "columns_types = {key: value['dtype'] for key, value in data_schema.items()}\n",
    "shark_attacks = shark_attacks.astype(columns_types)\n",
    "shark_attacks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean categories\n",
    "for column in shark_attacks.select_dtypes(include=['category']).columns:\n",
    "    shark_attacks[column] = shark_attacks[column].astype('string')\n",
    "    shark_attacks[column] = pd.Categorical(shark_attacks[column], categories=set(data_schema[column]['categories']), ordered=True)\n",
    "    shark_attacks[column] = shark_attacks[column].where(shark_attacks[column].isin(data_schema[column]['categories']), other=data_schema[column]['categories'][-1])\n",
    "    shark_attacks[column] = shark_attacks[column].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "#shark_attacks.to_csv('shark_attacks_cleaned.csv', index=False)\n",
    "display(shark_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks_clean = shark_attacks.copy()\n",
    "shark_attacks_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks['species'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hennings functions\n",
    "# Merge categories : (*categories to be merged, target) - Henning\n",
    "\n",
    "\n",
    "\"\"\" shark_attacks['type'] = shark_attacks['type'].apply(merge_values, args=(\n",
    "    \"Invalid\", \"Questionable\", \"Unconfirmed\", \"?\", 'Unverified', 'Under investigation'))\n",
    "shark_attacks['type'] = shark_attacks['type'].apply(\n",
    "    merge_values, args=(\"Provoked\", \" Provoked\"))\n",
    "shark_attacks['type'] = shark_attacks['type'].apply(\n",
    "    merge_values, args=(\"Watercraft\", \"Boat\"))  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linh functions\n",
    "# Strip function : strips spaces - Linh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df_cleaned['location'] = df_cleaned['location'].astype(str)\n",
    "\n",
    "\n",
    "def clean_data(location):\n",
    "    location = re.sub(r'\\d{1,2}Âº[NS],\\s*\\d{1,3}Âº[EW]', '', location)\n",
    "    location = re.sub(r'\\(.*?\\)', '', location)\n",
    "    location = re.sub(r'\\s+', ' ', location)\n",
    "    return location.title()\n",
    "\n",
    "\n",
    "df_cleaned['location'] = df_cleaned['location'].apply(clean_data)\n",
    "df_cleaned['location'].head(1000) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" categories = [\n",
    "    (r\"swimming|wading\", \"Swimming\"),\n",
    "    (r\"surf|boogie boarding|paddle|foil\", \"Surfing\"),\n",
    "    (r\"fish|fishing|spearfish|kayak\", \"Fishing\"),\n",
    "    (r\"diving|scuba|freediving|snorkel\", \"Diving\"),\n",
    "    (r\"sit|stand\", \"Passive\"),\n",
    "] \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" df_cleaned['activity'] = df_cleaned['activity'].apply(categorize_activity)\n",
    "df_cleaned.head(100) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricardo functions\n",
    "# Replace as Nan, Nat, ... function - Ricardo\n",
    "# Remove obvious duplicate (entire line) - Ricardo\n",
    "# Remove fuzzy duplicates (case number? dates?) - Ricardo\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\" replace_to_nan(shark_attacks[\"Name\"].fillna(np.nan).str.strip(),['male', 'female'],np.nan)\n",
    "shark_attacks \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jp functions\n",
    "\n",
    "# replacements\n",
    "\"\"\" replacements_test_species = [\n",
    "    (r'^.*([Tt]iger).*$', 'TIGER SHARK'),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "replacements_test_time = [\n",
    "    (r'^.*((0[0-2]|23)h|([nN]ight|[dD]ark)).*$', 'NIGHT'),\n",
    "    (r'^.*((0[3-6])h|([dD]awn|[sS]unrise|[dD]aybreak)).*$', 'DAWN'),\n",
    "    (r'^.*((0[7-9]|10)h.*$|([mM]orning|^[aA]\\.?[mM])).*$', 'MORNING'),\n",
    "    (r'^.*((1[1-4])h.*$|([nN]oon|[mM]idday|[lL]unch)).*$', 'NOON'),\n",
    "    (r'^.*((1[5-8])h.*$|([aA]fternoon|^[pP]\\.?[mM])).*$', 'AFTERNOON'),\n",
    "    (r'^.*((19|2[0-2])h.*$|([dD]usk|[sS]unset|[eE]vening)).*$', 'DUSK'),\n",
    "] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source, PDF, Case Number as possible duplicate finder or year / date fill\n",
    "relevant_columns = ['date', 'Year', 'type', 'country', 'state', 'location', 'activity',\n",
    "                    'Name', 'Sex', 'Age', 'injury', 'time', 'Species', 'Source', 'pdf', 'href formula', 'href']\n",
    "business_relevant_columns = ['date', 'type', 'country',\n",
    "                             'state', 'location', 'activity', 'injury', 'time']\n",
    "\n",
    "# Henning : Date, Type\n",
    "# Ricardo : Country, State\n",
    "# Linh : Location, Activity\n",
    "# Jp : Injury, Time\n",
    "\n",
    "# Type : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Provoked, Unprovoked, Invalid\n",
    "# Date : datetime : Clean \"Reported\" - Harmonize Format - Cast weird into NaT. Final => Dates (as datetime), NaT\n",
    "# Country : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# State : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Location : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Activity : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Few categories to be determined\n",
    "# Injury : category : Merge columns based on keywords. Nan into other. Final => Fatality, Injury, Other\n",
    "# Time : category : Cast into categories Final => morning (6-10) noon (10-14) afternoon( 14-18) dusk (18-22) night (22 - 2) dawn (2-6) maybe as integers (0-5)\n",
    "\n",
    "\"\"\" display(time_replace_test.value_counts())\n",
    "where_test = time_replace_test.where(time_replace_test.isin(valid_categories))\n",
    "where_test = where_test.astype('category')\n",
    "where_test \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source, PDF, Case Number as possible duplicate finder or year / date fill\n",
    "relevant_columns = ['date', 'Year', 'type', 'country', 'state', 'location', 'activity',\n",
    "                    'Name', 'Sex', 'Age', 'injury', 'time', 'Species', 'Source', 'pdf', 'href formula', 'href']\n",
    "business_relevant_columns = ['date', 'type', 'country',\n",
    "                             'state', 'location', 'activity', 'injury', 'time']\n",
    "\n",
    "# Henning : Date, Type\n",
    "# Ricardo : Country, State\n",
    "# Linh : Location, Activity\n",
    "# Jp : Injury, Time\n",
    "\n",
    "# Type : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Provoked, Unprovoked, Invalid\n",
    "# Date : datetime : Clean \"Reported\" - Harmonize Format - Cast weird into NaT. Final => Dates (as datetime), NaT\n",
    "# Country : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# State : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Location : string : Strip spaces - Formatting - Replace weird characters - cast weird values as NaN => Strings, Nan\n",
    "# Activity : category : Merge some columns based on categories. Trim labels. Nan into invalid. Final => Few categories to be determined\n",
    "# Injury : category : Merge columns based on keywords. Nan into other. Final => Fatality, Injury, Other\n",
    "# Time : category : Cast into categories Final => morning (6-10) noon (10-14) afternoon( 14-18) dusk (18-22) night (22 - 2) dawn (2-6) maybe as integers (0-5)\n",
    "\n",
    "# Todo\n",
    "# Remove obvious duplicate (entire line) - Ricardo\n",
    "# Remove fuzzy duplicates (case number? dates?) - Ricardo\n",
    "\n",
    "# Functions :\n",
    "# Merge categories : (*categories to be merged, target) - Henning\n",
    "# Strip function : strips spaces - Linh\n",
    "# Replace as Nan, Nat, ... function - Ricardo\n",
    "# DONE - Replace by keyword function - Jp\n",
    "# DONE - Cast to dateTime function\n",
    "# Matching function (find similarities, keyword based?)\n",
    "# DONE - Reformat dates, strings\n",
    "# Filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_attacks['Name'].value_counts()\n",
    "\n",
    "\n",
    "def get_fname(row):\n",
    "    return str(row).split()[0]\n",
    "\n",
    "\n",
    "shark_attacks['first_name'] = shark_attacks['Name'].apply(get_fname)\n",
    "\n",
    "shark_attacks['first_name'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INJURY\n",
    "\n",
    "## Problems\n",
    "- Some are non-human damages (boat, kayak, boards)\n",
    "- Some are non injuries (touched shark)\n",
    "- Some don't have details\n",
    "- Fatalities flags are non consistent\n",
    "- Some incident are post-mortem\n",
    "- Some are not incidents ('Aboriginal rock carving depicts man being attacked by a shark')\n",
    "- Nan\n",
    "\n",
    "## Additional\n",
    "- Some provoked details that could be useful if missing elsewhere\n",
    "\n",
    "## Solutions\n",
    "- 3 categories : \n",
    "    - Fatality\n",
    "    - Injury\n",
    "    - Other\n",
    "\n",
    "- Keyword(s) based search / replace ?\n",
    "\n",
    "### TIME\n",
    "\n",
    "## Problems\n",
    "- Lots of Nan\n",
    "- Some are times (12h00,...), other are time of day (morning,...)\n",
    "- Some are text\n",
    "- Some are ranges\n",
    "- Some are calculations\n",
    "- Some are 12h based, other 24h based\n",
    "- Some maybe duplicates \n",
    "- Some are misplaced data\n",
    "\n",
    "## Solutions\n",
    "- 2 types :\n",
    "    - Time (int? str?)\n",
    "    - Unknown / NaN / None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install geopandas if you haven't already\n",
    "\n",
    "\n",
    "# Create a GeoDataFrame with points\n",
    "data = {\n",
    "    'City': ['San Francisco', 'Los Angeles', 'New York'],\n",
    "    'Latitude': [37.7749, 34.0522, 40.7128],\n",
    "    'Longitude': [-122.4194, -118.2437, -74.0060]\n",
    "}\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    data, geometry=gpd.points_from_xy(data['Longitude'], data['Latitude'])\n",
    ")\n",
    "\n",
    "# Load a world basemap\n",
    "world = gpd.read_file('maps/land_map.shp')\n",
    "\n",
    "# Plot the world basemap and the points\n",
    "ax = world.plot(figsize=(10, 6))\n",
    "ax.axis('off')\n",
    "gdf.plot(ax=ax, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'path_to_shapefile.shp' with the path to your custom shapefile\n",
    "custom_map = gpd.read_file('path_to_shapefile.shp')\n",
    "\n",
    "# Plot the custom map\n",
    "ax = custom_map.plot(figsize=(10, 6))\n",
    "\n",
    "# Add your points of interest (from the earlier gdf)\n",
    "gdf.plot(ax=ax, color='red')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
